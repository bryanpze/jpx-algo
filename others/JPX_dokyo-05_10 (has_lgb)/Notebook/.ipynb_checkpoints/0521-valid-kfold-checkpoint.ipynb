{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-21T04:11:41.038694Z",
     "iopub.status.busy": "2022-05-21T04:11:41.038334Z",
     "iopub.status.idle": "2022-05-21T04:11:43.491801Z",
     "shell.execute_reply": "2022-05-21T04:11:43.491101Z",
     "shell.execute_reply.started": "2022-05-21T04:11:41.038604Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from math import ceil\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split,KFold, StratifiedKFold\n",
    "import lightgbm as lgb \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:12:00.249934Z",
     "iopub.status.busy": "2022-05-21T04:12:00.249137Z",
     "iopub.status.idle": "2022-05-21T04:12:06.324626Z",
     "shell.execute_reply": "2022-05-21T04:12:06.323937Z",
     "shell.execute_reply.started": "2022-05-21T04:12:00.249896Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:12:06.326561Z",
     "iopub.status.busy": "2022-05-21T04:12:06.325811Z",
     "iopub.status.idle": "2022-05-21T04:12:12.895484Z",
     "shell.execute_reply": "2022-05-21T04:12:12.894881Z",
     "shell.execute_reply.started": "2022-05-21T04:12:06.326523Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[data['Target'].notnull()].reset_index(drop = True)\n",
    "\n",
    "for col in ['Open','High','Low','Close']:\n",
    "    data[col] = data.groupby('SecuritiesCode', sort=False)[col].apply(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:12:12.896891Z",
     "iopub.status.busy": "2022-05-21T04:12:12.896535Z",
     "iopub.status.idle": "2022-05-21T04:12:41.585613Z",
     "shell.execute_reply": "2022-05-21T04:12:41.584674Z",
     "shell.execute_reply.started": "2022-05-21T04:12:12.896862Z"
    }
   },
   "outputs": [],
   "source": [
    "## 총 거래액 생성\n",
    "data['amount'] = data['Close'] * data['Volume'] # amount\n",
    "\n",
    "## 주기 함수 생성\n",
    "min_date = data['Date'].min()\n",
    "\n",
    "def time_encoder(date):\n",
    "    dt = date - min_date\n",
    "    dt = dt.days\n",
    "    \n",
    "    while dt >= 180:\n",
    "        dt -= 180\n",
    "    output = np.cos(2*np.pi*dt/180)\n",
    "    \n",
    "    return output\n",
    "\n",
    "data['cycle'] = data['Date'].apply(lambda x: time_encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:12:41.587630Z",
     "iopub.status.busy": "2022-05-21T04:12:41.587391Z",
     "iopub.status.idle": "2022-05-21T04:13:16.734727Z",
     "shell.execute_reply": "2022-05-21T04:13:16.733731Z",
     "shell.execute_reply.started": "2022-05-21T04:12:41.587601Z"
    }
   },
   "outputs": [],
   "source": [
    "def week_of_month(date):\n",
    "    day = date.day\n",
    "    wom = int(np.ceil(day / 7.0))\n",
    "    \n",
    "    return wom\n",
    "\n",
    "def day_feature(data):    \n",
    "    day_df = data.groupby('Date').sum()[['amount','Close']].reset_index()\n",
    "    day_df['diff'] = day_df['Close'].diff()\n",
    "    day_df['shift1'] = day_df['Close'].shift(1)\n",
    "\n",
    "    day_df['day_roc'] = (day_df['diff'] / day_df['shift1']) * 100\n",
    "    day_df.rename({'amount':'day_amount'}, axis=1, inplace=True)\n",
    "    day_df = day_df[['Date','day_amount','day_roc']]\n",
    "\n",
    "    data = pd.merge(data, day_df, on = 'Date', how='left')\n",
    "    \n",
    "    return data\n",
    "\n",
    "stock_list = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\")\n",
    "stock_list = stock_list[['SecuritiesCode','Section/Products','NewMarketSegment','33SectorName','17SectorName']]\n",
    "\n",
    "def day_list_feature(data):\n",
    "    data = pd.merge(data, stock_list, on = 'SecuritiesCode', how = 'left')\n",
    "    segs = ['Section/Products','NewMarketSegment','33SectorName','17SectorName']\n",
    "    \n",
    "    for seg in segs:\n",
    "        day_df = data.groupby(['Date',seg]).sum()[['amount','Close']].reset_index()\n",
    "        \n",
    "        tmp = pd.DataFrame()\n",
    "        for unique_seg in data[seg].unique():\n",
    "            day_unique_df = day_df[day_df[seg] == unique_seg].reset_index(drop = True)\n",
    "\n",
    "            day_unique_df['diff'] = day_unique_df['Close'].diff()\n",
    "            day_unique_df['shift1'] = day_unique_df['Close'].shift(1)\n",
    "\n",
    "            day_unique_df['day_roc'] = (day_unique_df['diff'] / day_unique_df['shift1']) * 100\n",
    "            \n",
    "            tmp = pd.concat([tmp, day_unique_df])\n",
    "            \n",
    "        tmp.rename({'amount': seg + '_amount', 'day_roc': seg + '_roc'}, axis=1, inplace=True)\n",
    "        tmp.drop(['diff','shift1','Close'], axis=1, inplace=True)\n",
    "        data = pd.merge(data, tmp, on = ['Date',seg], how='left')\n",
    "        \n",
    "#     data.drop(['Section/Products','NewMarketSegment','33SectorName','17SectorName'], axis=1, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data['weekday'] = data[\"Date\"].apply(lambda x: x.weekday())\n",
    "data['weeknum'] = data[\"Date\"].apply(lambda x: week_of_month(x))\n",
    "\n",
    "data = day_feature(data)\n",
    "data = day_list_feature(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:16.736389Z",
     "iopub.status.busy": "2022-05-21T04:13:16.736050Z",
     "iopub.status.idle": "2022-05-21T04:13:21.120686Z",
     "shell.execute_reply": "2022-05-21T04:13:21.120057Z",
     "shell.execute_reply.started": "2022-05-21T04:13:16.736356Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.pivot_table(data, index = 'SecuritiesCode', columns = 'Date', values = 'Target')\n",
    "df = df.transpose().dropna().transpose()\n",
    "\n",
    "# epsilon, 최소 샘플 개수 설정\n",
    "model = DBSCAN(eps=0.8, min_samples=5)\n",
    "\n",
    "# 군집화 모델 학습 및 클러스터 예측 결과 반환\n",
    "model.fit(df)\n",
    "df['cluster'] = model.fit_predict(df)\n",
    "df = df.reset_index()[['SecuritiesCode','cluster']]\n",
    "\n",
    "data = pd.merge(data, df, on = 'SecuritiesCode', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:21.122409Z",
     "iopub.status.busy": "2022-05-21T04:13:21.122171Z",
     "iopub.status.idle": "2022-05-21T04:13:21.149463Z",
     "shell.execute_reply": "2022-05-21T04:13:21.148345Z",
     "shell.execute_reply.started": "2022-05-21T04:13:21.122379Z"
    }
   },
   "outputs": [],
   "source": [
    "def Stochastic(df, n=14, m=5, t=5):    \n",
    "    # n일 중 최고가\n",
    "    ndays_high = df['High'].rolling(window = n, min_periods=1).max()\n",
    "    # n일 중 최저가\n",
    "    ndays_low = df['Low'].rolling(window = n, min_periods=1).max()\n",
    "    \n",
    "    # Fast %K 계산\n",
    "    fast_k = ((df['Close'] - ndays_low) / (ndays_high - ndays_low)) * 100\n",
    "    # Fast %D (Slow %K) 계산\n",
    "    slow_k = fast_k.ewm(span=m).mean()\n",
    "    # Slow %d 계산\n",
    "    slow_d = slow_k.ewm(span=t).mean()\n",
    "    \n",
    "    # 값 추가\n",
    "    df['fast_k'] = fast_k\n",
    "    df['fast_d'] = slow_k\n",
    "    df['slow_d'] = slow_d\n",
    "    \n",
    "    return df\n",
    "\n",
    "def SMA(data, period=30, column = 'Close'):\n",
    "    return data[column].rolling(window=period).mean()\n",
    "\n",
    "def RSI(data, period = 14, column = 'Close'):\n",
    "    delta = data[column].diff(1)\n",
    "    delta = delta.dropna()\n",
    "    \n",
    "    up = delta.copy()\n",
    "    down = delta.copy()\n",
    "    \n",
    "    up[up < 0] = 0\n",
    "    down[down > 0] = 0\n",
    "    \n",
    "    data['delta'] = delta\n",
    "    data['up'] = up\n",
    "    data['down'] = down\n",
    "    \n",
    "    AVG_Gain = SMA(data, period, column = 'up')\n",
    "    AVG_Loss = abs(SMA(data, period, column = 'down'))\n",
    "    \n",
    "    RS = AVG_Gain / AVG_Loss\n",
    "    RSI = 100.0 - (100.0/(1.0 + RS))\n",
    "    \n",
    "    data['AVG_Gain'] = AVG_Gain\n",
    "    data['AVG_Loss'] = AVG_Loss\n",
    "    data['RS'] = RS\n",
    "    data['RSI'] = RSI\n",
    "    \n",
    "    return data\n",
    "\n",
    "def OBV(data):\n",
    "    OBV = [0]\n",
    "    for i in tqdm(range(1,len(data))):\n",
    "        if data['Close'][i] > data['Close'][i-1]:\n",
    "            OBV.append(OBV + data['Volume'][i])\n",
    "        elif data['Close'][i] < data['Close'][i-1]:\n",
    "            OBV.append(OBV - data['Volume'][i])\n",
    "        else:\n",
    "            OBV.append(OBV[-1])\n",
    "    data['OBV'] = OBV\n",
    "    data['OBV_EMA'] = data['OBV'].ewm(com = 20).mean()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def MFI(data):\n",
    "    # 10일(거래일 기준으로 2주 동안) 기준의 현금흐름지표를 구하는 코드\n",
    "    data['avg_price'] = (data['High']+data['Low']+data['Close'])/3\n",
    "    data['PMF'] = 0\n",
    "    data['NMF'] = 0\n",
    "    \n",
    "    for i in range(len(data['Close'])-1):\n",
    "        # 당일의 중심가격이 전일의 중심가격보다 크면 긍정적 현금흐름\n",
    "        if data['avg_price'].values[i] < data['avg_price'].values[i+1]:\n",
    "            data['PMF'].values[i+1] = data['avg_price'].values[i+1]*data['Volume'].values[i+1]\n",
    "            data['NMF'].values[i+1] = 0\n",
    "        # 당일의 중심가격이 전일의 중심가격보다 작거나 같으면 부정적 현금흐름\n",
    "        else:\n",
    "            data['NMF'].values[i+1] = data['avg_price'].values[i+1]*data['Volume'].values[i+1]\n",
    "            data['PMF'].values[i+1] = 0\n",
    "\n",
    "    data['MFR'] = data['PMF'].rolling(window=10).sum()/data['NMF'].rolling(window=10).sum()\n",
    "    data['MFI10'] = 100 - 100/(1+data['MFR'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def CCI(data):\n",
    "    data['TP'] = (data['High'] + data['Low'] + data['Close']) / 3\n",
    "    data['SMA'] = data['TP'].rolling(window=20).mean()\n",
    "    data['MAD'] = data['TP'].rolling(window=20).apply(lambda x: pd.Series(x).mad())\n",
    "    data['CCI'] = (data['TP'] - data['SMA']) / (0.015 * data['MAD'])\n",
    "    \n",
    "    data.drop(['TP','SMA','MAD'], axis=1, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def MACD(data, m_NumFast=12, m_NumSlow=26, m_NumSignal=9):\n",
    "    data['EMAFast'] = data['Close'].ewm(span = m_NumFast, min_periods = m_NumFast - 1).mean()\n",
    "    data['EMASlow'] = data['Close'].ewm(span = m_NumSlow, min_periods = m_NumSlow - 1).mean()\n",
    "    data['MACD'] = data['EMAFast'] - data['EMASlow']\n",
    "    data['MACDSignal'] = data['MACD'].ewm(span = m_NumSignal, min_periods = m_NumSignal-1).mean()\n",
    "    data['MACDDiff'] = data['MACD'] - data['MACDSignal']\n",
    "    \n",
    "    return data\n",
    "\n",
    "def bollinger(data):\n",
    "    data['ma20'] = data['Close'].rolling(window=20).mean() # 20일 이동평균\n",
    "    data['stddev'] = data['Close'].rolling(window=20).std() # 20일 이동표준편차\n",
    "    data['band_upper'] = data['ma20'] + 2*data['stddev'] # 상단밴드\n",
    "    data['band_lower'] = data['ma20'] - 2*data['stddev'] # 하단밴드\n",
    "    \n",
    "    data.drop(['ma20','stddev'], axis = 1, inplace = True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def williams(data, n_days = 14):\n",
    "    data['low_min'] = data['Low'].rolling(window = n_days, center = False).min()\n",
    "    data['high_max'] = data['High'].rolling(window = n_days, center = False).max()\n",
    "    \n",
    "    data['willr'] = ((data['high_max'] - data['Close']) / (data['high_max'] - data['low_min'])) * -100\n",
    "    \n",
    "    return data\n",
    "\n",
    "def ROC(data):\n",
    "    data['diff'] = data['Close'].diff()\n",
    "    data['shift1'] = data['Close'].shift(1)\n",
    "    \n",
    "    data['rate_of_change'] = (data['diff'] / data['shift1']) * 100\n",
    "    \n",
    "    data.drop(['diff','shift1'], axis=1, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:21.151077Z",
     "iopub.status.busy": "2022-05-21T04:13:21.150760Z",
     "iopub.status.idle": "2022-05-21T04:13:22.479782Z",
     "shell.execute_reply": "2022-05-21T04:13:22.478894Z",
     "shell.execute_reply.started": "2022-05-21T04:13:21.151048Z"
    }
   },
   "outputs": [],
   "source": [
    "df = data[data['SecuritiesCode'].apply(lambda x: x in [1301, 1332, 1333, 1376, 1377, 1379, 1381, 1407, 4168, 4169])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:22.482181Z",
     "iopub.status.busy": "2022-05-21T04:13:22.481959Z",
     "iopub.status.idle": "2022-05-21T04:13:22.808718Z",
     "shell.execute_reply": "2022-05-21T04:13:22.807846Z",
     "shell.execute_reply.started": "2022-05-21T04:13:22.482155Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame()\n",
    "\n",
    "for stock in tqdm(df['SecuritiesCode'].unique()):\n",
    "    tmp_stock = df[df['SecuritiesCode'] == stock].reset_index(drop = True)\n",
    "    \n",
    "    tmp_stock = Stochastic(tmp_stock)\n",
    "    tmp_stock = RSI(tmp_stock)\n",
    "    tmp_stock = MACD(tmp_stock)\n",
    "    tmp_stock = bollinger(tmp_stock)\n",
    "    tmp_stock = williams(tmp_stock)\n",
    "    tmp_stock = ROC(tmp_stock)\n",
    "    \n",
    "    tmp = pd.concat([tmp, tmp_stock])\n",
    "    \n",
    "df = tmp.copy()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:22.810517Z",
     "iopub.status.busy": "2022-05-21T04:13:22.810224Z",
     "iopub.status.idle": "2022-05-21T04:13:22.838507Z",
     "shell.execute_reply": "2022-05-21T04:13:22.837870Z",
     "shell.execute_reply.started": "2022-05-21T04:13:22.810478Z"
    }
   },
   "outputs": [],
   "source": [
    "## 이동평균\n",
    "df[\"close_mv5\"] = df[\"Close\"].rolling(5, min_periods=5).mean()\n",
    "df[\"close_mv10\"] = df[\"Close\"].rolling(10, min_periods=10).mean()\n",
    "df[\"close_mv20\"] = df[\"Close\"].rolling(20, min_periods=20).mean()\n",
    "\n",
    "df[\"volume_mv5\"] = df[\"Volume\"].rolling(5, min_periods=5).mean()\n",
    "df[\"volume_mv10\"] = df[\"Volume\"].rolling(10, min_periods=10).mean()\n",
    "df[\"volume_mv20\"] = df[\"Volume\"].rolling(20, min_periods=20).mean()\n",
    "\n",
    "df[\"amount_mv5\"] = df[\"amount\"].rolling(5, min_periods=5).mean()\n",
    "df[\"amount_mv10\"] = df[\"amount\"].rolling(10, min_periods=10).mean()\n",
    "df[\"amount_mv20\"] = df[\"amount\"].rolling(20, min_periods=20).mean()\n",
    "\n",
    "\n",
    "## 과거 시점 데이터\n",
    "tmp_df = pd.DataFrame()\n",
    "tmp_cols = []\n",
    "\n",
    "for i in range(1,6,1):\n",
    "    tmp_df = pd.concat([tmp_df, df[\"Close\"].shift(i).to_frame()], axis=1)\n",
    "    tmp_cols.append(\"close_\" + str(i) + \"shift\")\n",
    "tmp_df.columns = tmp_cols\n",
    "df = pd.concat([df, tmp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:22.840087Z",
     "iopub.status.busy": "2022-05-21T04:13:22.839365Z",
     "iopub.status.idle": "2022-05-21T04:13:22.895408Z",
     "shell.execute_reply": "2022-05-21T04:13:22.894879Z",
     "shell.execute_reply.started": "2022-05-21T04:13:22.840054Z"
    }
   },
   "outputs": [],
   "source": [
    "del df['ExpectedDividend']\n",
    "\n",
    "df['SupervisionFlag'] = df['SupervisionFlag'].apply(lambda x: 1 if x == False else 0)\n",
    "\n",
    "cols_del = ['RowId','Date','SecuritiesCode','Section/Products','NewMarketSegment','33SectorName','17SectorName','rank']\n",
    "# cols_null = [col for col in df.columns if df[col].isnull().sum() > 0]\n",
    "\n",
    "cluster_cols = ['day_roc','RSI','day_amount','AVG_Loss','AVG_Gain','amount_mv5']\n",
    "col_names = [a + '_cluster' for a in cluster_cols]\n",
    "\n",
    "tmp = df.groupby(['Date','cluster']).mean()[cluster_cols]\n",
    "tmp.columns = col_names\n",
    "tmp.reset_index(inplace=True)\n",
    "\n",
    "df = pd.merge(df, tmp, on = ['Date','cluster'], how = 'left')\n",
    "\n",
    "df = df.dropna()\n",
    "features = list(set(df.columns) - set(cols_del))\n",
    "features.remove('Target')\n",
    "\n",
    "print(len(features))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:22.897153Z",
     "iopub.status.busy": "2022-05-21T04:13:22.896653Z",
     "iopub.status.idle": "2022-05-21T04:13:34.595389Z",
     "shell.execute_reply": "2022-05-21T04:13:34.593704Z",
     "shell.execute_reply.started": "2022-05-21T04:13:22.897124Z"
    }
   },
   "outputs": [],
   "source": [
    "## cv로 stratified -> 점수확인용\n",
    "target = 'Target'\n",
    "evals_result_1 = []\n",
    "\n",
    "def cv_v1 (df, features, target):    \n",
    "    max_date = df['Date'].max()\n",
    "    day_standard = 50\n",
    "\n",
    "    df['tmp'] = df['Date'].apply(lambda x: (max_date - x).days)\n",
    "    df['tmp'] = df['tmp'].apply(lambda x: 'test' if ((x < day_standard) | (x >= day_standard*6 and x < day_standard*7) \n",
    "                                                    | (x >= day_standard*13 and x < day_standard*14)\n",
    "                                                    | (x >= day_standard*20 and x < day_standard*21)\n",
    "                                                    | (x >= day_standard*28 and x < day_standard*29)) else 'train')\n",
    "    \n",
    "    train_set = df[df['tmp'] == 'train'].reset_index(drop = True)\n",
    "    valid_set = df[df['tmp'] == 'test'].reset_index(drop = True)\n",
    "\n",
    "    del train_set['tmp']\n",
    "    del valid_set['tmp']\n",
    "\n",
    "    X_train = train_set[features]\n",
    "    y_train = train_set[target]\n",
    "    X_valid = valid_set[features]\n",
    "    y_valid = valid_set[target]\n",
    "\n",
    "    params = {\n",
    "                'learning_rate' : 0.05,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'regression',\n",
    "                'tweedie_variance_power': 1.1,\n",
    "                'metric': 'mae',\n",
    "                'sub_row' : 0.75,\n",
    "                'lambda_l2' : 0.1\n",
    "            }\n",
    "\n",
    "    preds = []\n",
    "    i = 1\n",
    "\n",
    "    kf = KFold(5)\n",
    "\n",
    "    print('CV Version 1')\n",
    "    for tr_id, val_id in kf.split(X_train, y_train) : \n",
    "        X_tr = X_train.iloc[tr_id]\n",
    "        y_tr = y_train.iloc[tr_id]\n",
    "\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(X_tr, y_tr, train_size=0.8,random_state=42)\n",
    "        train_ds = lgb.Dataset(train_x, label=train_y)\n",
    "        val_ds = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "        print('-' * 100)\n",
    "        print('{}번째 학습'.format(i))\n",
    "        model = lgb.train(params,\n",
    "                      train_ds,\n",
    "                      1500,\n",
    "                      val_ds,\n",
    "                      verbose_eval = 100,\n",
    "                      early_stopping_rounds = 100\n",
    "                     ) \n",
    "        pred = model.predict(X_valid)\n",
    "        preds.append(pred)\n",
    "\n",
    "        evals_result_1.append([*model.best_score.values()][0].get('l1'))\n",
    "        i += 1\n",
    "\n",
    "    model_pred = np.mean(preds, axis = 0)\n",
    "    \n",
    "    # Score 계산\n",
    "    valid_set['pred'] = model_pred\n",
    "    \n",
    "    valid_set = valid_set[['Date','SecuritiesCode','Target','pred']]\n",
    "\n",
    "    valid_set['rank'] = valid_set.groupby('Date').rank(ascending=False,method=\"first\")[['Target']] - 1\n",
    "    tmp = valid_set.groupby('Date').max()[['rank']].reset_index()\n",
    "    tmp.rename({'rank':'rank_bottom'}, axis=1, inplace=True)\n",
    "\n",
    "    valid_set = pd.merge(valid_set, tmp, on = 'Date', how = 'left')\n",
    "    valid_set['rank_bottom'] = valid_set['rank_bottom'] - valid_set['rank']\n",
    "\n",
    "    weights = np.linspace(start=2, stop=1, num=200)\n",
    "\n",
    "    tmp = pd.DataFrame()\n",
    "    tmp['rank'] = np.arange(0,200,1)\n",
    "    tmp['rank_bottom'] = np.arange(0,200,1)\n",
    "    tmp['weights'] = weights\n",
    "\n",
    "    valid_set = pd.merge(valid_set, tmp[['rank','weights']], on = 'rank', how = 'left')\n",
    "    valid_set = pd.merge(valid_set, tmp[['rank_bottom','weights']], on = 'rank_bottom', how = 'left')\n",
    "\n",
    "    valid_set['calc_weights_x'] = valid_set['Target'] * valid_set['weights_x']\n",
    "    valid_set['calc_weights_y'] = valid_set['Target'] * valid_set['weights_y']\n",
    "    valid_set.dropna(inplace=True)\n",
    "\n",
    "    Sup = valid_set.groupby('Date').sum()[\"calc_weights_x\"] / valid_set.groupby('Date').mean()['calc_weights_x']\n",
    "    Sdown = valid_set.groupby('Date').sum()[\"calc_weights_y\"] / valid_set.groupby('Date').mean()['calc_weights_y']\n",
    "    daily_spread_return = Sup - Sdown\n",
    "    score = np.mean(daily_spread_return) / np.std(daily_spread_return)\n",
    "    \n",
    "    # mae 계산\n",
    "    mae = mean_absolute_error(y_valid, model_pred)\n",
    "    print(mae)\n",
    "    \n",
    "    return evals_result_1, mae, score\n",
    "\n",
    "evals_result_1, evals_mae_1, score_1 = cv_v1(df, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:34.598721Z",
     "iopub.status.busy": "2022-05-21T04:13:34.598439Z",
     "iopub.status.idle": "2022-05-21T04:13:39.733981Z",
     "shell.execute_reply": "2022-05-21T04:13:39.733000Z",
     "shell.execute_reply.started": "2022-05-21T04:13:34.598686Z"
    }
   },
   "outputs": [],
   "source": [
    "## cv로 stratified -> 점수확인용\n",
    "target = 'Target'\n",
    "evals_result_2 = []\n",
    "\n",
    "def cv_v2 (df, features, target):    \n",
    "\n",
    "    df['yymm'] = df['Date'].apply(lambda x: str(x)[:4] + str(x)[5:7])\n",
    "\n",
    "    fold1_train = df[(df['yymm'] >= '201702') & (df['yymm'] <= '201712')].reset_index(drop = True)\n",
    "    fold2_train = df[(df['yymm'] >= '201803') & (df['yymm'] <= '201811')].reset_index(drop = True)\n",
    "    fold3_train = df[(df['yymm'] >= '201902') & (df['yymm'] <= '201910')].reset_index(drop = True)\n",
    "    fold4_train = df[(df['yymm'] >= '202001') & (df['yymm'] <= '202009')].reset_index(drop = True)\n",
    "    fold5_train = df[(df['yymm'] >= '202006') & (df['yymm'] <= '202012')].reset_index(drop = True)\n",
    "\n",
    "#     valid_train = df[(df['yymm'] >= '202103') & (df['yymm'] <= '202109')].reset_index(drop = True)\n",
    "\n",
    "    fold1_test = df[df['yymm'] == '201802'].reset_index(drop = True)\n",
    "    fold2_test = df[df['yymm'] == '201901'].reset_index(drop = True)\n",
    "    fold3_test = df[df['yymm'] == '201912'].reset_index(drop = True)\n",
    "    fold4_test = df[df['yymm'] == '202011'].reset_index(drop = True)\n",
    "    fold5_test = df[df['yymm'] == '202110'].reset_index(drop = True)\n",
    "\n",
    "    valid_test = df[df['yymm'] == '202111'].reset_index(drop = True)\n",
    "\n",
    "    train_dfs = [fold1_train, fold2_train, fold3_train, fold4_train, fold5_train]\n",
    "    test_dfs = [fold1_test, fold2_test, fold3_test, fold4_test, fold5_test]\n",
    "    \n",
    "    params = {\n",
    "                'learning_rate' : 0.05,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'regression',\n",
    "                'tweedie_variance_power': 1.1,\n",
    "                'metric': 'mae',\n",
    "                'sub_row' : 0.75,\n",
    "                'lambda_l2' : 0.1\n",
    "            }\n",
    "\n",
    "    preds = []\n",
    "    i = 1\n",
    "\n",
    "    kf = KFold(5)\n",
    "\n",
    "    print('CV Version 2')\n",
    "    for train, test in zip(train_dfs, test_dfs):\n",
    "        train_x = train[features]\n",
    "        train_y = train[target]\n",
    "        valid_x = test[features]\n",
    "        valid_y = test[target]\n",
    "\n",
    "        train_ds = lgb.Dataset(train_x, label=train_y)\n",
    "        val_ds = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "        print('-' * 100)\n",
    "        print('{}번째 학습'.format(i))\n",
    "        model = lgb.train(params,\n",
    "                      train_ds,\n",
    "                      1500,\n",
    "                      val_ds,\n",
    "                      verbose_eval = 100,\n",
    "                      early_stopping_rounds = 100\n",
    "                     ) \n",
    "        pred = model.predict(valid_test[features])\n",
    "        preds.append(pred)\n",
    "\n",
    "        evals_result_2.append([*model.best_score.values()][0].get('l1'))\n",
    "        i += 1\n",
    "\n",
    "    model_pred = np.mean(preds, axis = 0)\n",
    "    \n",
    "    # Score 계산\n",
    "    valid_set = valid_test.copy()\n",
    "    valid_set['pred'] = model_pred\n",
    "    \n",
    "    valid_set = valid_set[['Date','SecuritiesCode','Target','pred']]\n",
    "\n",
    "    valid_set['rank'] = valid_set.groupby('Date').rank(ascending=False,method=\"first\")[['Target']] - 1\n",
    "    tmp = valid_set.groupby('Date').max()[['rank']].reset_index()\n",
    "    tmp.rename({'rank':'rank_bottom'}, axis=1, inplace=True)\n",
    "\n",
    "    valid_set = pd.merge(valid_set, tmp, on = 'Date', how = 'left')\n",
    "    valid_set['rank_bottom'] = valid_set['rank_bottom'] - valid_set['rank']\n",
    "\n",
    "    weights = np.linspace(start=2, stop=1, num=200)\n",
    "\n",
    "    tmp = pd.DataFrame()\n",
    "    tmp['rank'] = np.arange(0,200,1)\n",
    "    tmp['rank_bottom'] = np.arange(0,200,1)\n",
    "    tmp['weights'] = weights\n",
    "\n",
    "    valid_set = pd.merge(valid_set, tmp[['rank','weights']], on = 'rank', how = 'left')\n",
    "    valid_set = pd.merge(valid_set, tmp[['rank_bottom','weights']], on = 'rank_bottom', how = 'left')\n",
    "\n",
    "    valid_set['calc_weights_x'] = valid_set['Target'] * valid_set['weights_x']\n",
    "    valid_set['calc_weights_y'] = valid_set['Target'] * valid_set['weights_y']\n",
    "    valid_set.dropna(inplace=True)\n",
    "\n",
    "    Sup = valid_set.groupby('Date').sum()[\"calc_weights_x\"] / valid_set.groupby('Date').mean()['calc_weights_x']\n",
    "    Sdown = valid_set.groupby('Date').sum()[\"calc_weights_y\"] / valid_set.groupby('Date').mean()['calc_weights_y']\n",
    "    daily_spread_return = Sup - Sdown\n",
    "    score = np.mean(daily_spread_return) / np.std(daily_spread_return)\n",
    "    \n",
    "    # mae 계산\n",
    "    mae = mean_absolute_error(valid_test[target], model_pred)\n",
    "    print(mae)\n",
    "    \n",
    "    return evals_result_2, mae, score\n",
    "\n",
    "evals_result_2, evals_mae_2, score_2 = cv_v2(df, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:39.738219Z",
     "iopub.status.busy": "2022-05-21T04:13:39.737948Z",
     "iopub.status.idle": "2022-05-21T04:13:39.750461Z",
     "shell.execute_reply": "2022-05-21T04:13:39.748923Z",
     "shell.execute_reply.started": "2022-05-21T04:13:39.738190Z"
    }
   },
   "outputs": [],
   "source": [
    "print('CV1 내 스코어 평균: {0:0.5f}'.format(np.array(evals_result_1).mean()))\n",
    "print('CV2 내 스코어 평균: {0:0.5f}'.format(np.array(evals_result_2).mean()))\n",
    "print('CV1 내 스코어 STD: {0:0.5f}'.format(np.array(evals_result_1).std()))\n",
    "print('CV2 내 스코어 STD: {0:0.5f}'.format(np.array(evals_result_2).std()))\n",
    "print('CV1의 테스트 셋 MAE: {0:0.5f}'.format(np.array(evals_mae_1)))\n",
    "print('CV2의 테스트 셋 MAE: {0:0.5f}'.format(np.array(evals_mae_2)))\n",
    "print('CV1의 테스트 셋 Score: {0:0.5f}'.format(np.array(score_1)))\n",
    "print('CV2의 테스트 셋 Score: {0:0.5f}'.format(np.array(score_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:39.752197Z",
     "iopub.status.busy": "2022-05-21T04:13:39.751967Z",
     "iopub.status.idle": "2022-05-21T04:13:39.793451Z",
     "shell.execute_reply": "2022-05-21T04:13:39.792578Z",
     "shell.execute_reply.started": "2022-05-21T04:13:39.752171Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'CV1':evals_result_1,'CV2':evals_result_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:39.794919Z",
     "iopub.status.busy": "2022-05-21T04:13:39.794668Z",
     "iopub.status.idle": "2022-05-21T04:13:40.919598Z",
     "shell.execute_reply": "2022-05-21T04:13:40.918614Z",
     "shell.execute_reply.started": "2022-05-21T04:13:39.794879Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "            'learning_rate' : 0.05,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'tweedie_variance_power': 1.1,\n",
    "            'metric': 'mae',\n",
    "            'sub_row' : 0.75,\n",
    "            'lambda_l2' : 0.1\n",
    "        }\n",
    "    \n",
    "max_date = df['Date'].max()\n",
    "day_standard = 50\n",
    "\n",
    "df['tmp'] = df['Date'].apply(lambda x: (max_date - x).days)\n",
    "df['tmp'] = df['tmp'].apply(lambda x: 'test' if ((x < day_standard) | (x >= day_standard*6 and x < day_standard*7) \n",
    "                                                | (x >= day_standard*13 and x < day_standard*14)\n",
    "                                                | (x >= day_standard*20 and x < day_standard*21)\n",
    "                                                | (x >= day_standard*28 and x < day_standard*29)) else 'train')\n",
    "\n",
    "train_set = df[df['tmp'] == 'train'].reset_index(drop = True)\n",
    "valid_set = df[df['tmp'] == 'test'].reset_index(drop = True)\n",
    "\n",
    "del train_set['tmp']\n",
    "del valid_set['tmp']\n",
    "\n",
    "X_train = train_set[features]\n",
    "y_train = train_set[target]\n",
    "X_valid = valid_set[features]\n",
    "y_valid = valid_set[target]\n",
    "\n",
    "train_ds = lgb.Dataset(X_train, label=y_train)\n",
    "val_ds = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "print('-' * 100)\n",
    "print('{}번째 학습'.format(i))\n",
    "model = lgb.train(params,\n",
    "              train_ds,\n",
    "              1500,\n",
    "              val_ds,\n",
    "              verbose_eval = 100,\n",
    "              early_stopping_rounds = 100\n",
    "             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T04:13:40.921426Z",
     "iopub.status.busy": "2022-05-21T04:13:40.921151Z",
     "iopub.status.idle": "2022-05-21T04:13:41.566465Z",
     "shell.execute_reply": "2022-05-21T04:13:41.565524Z",
     "shell.execute_reply.started": "2022-05-21T04:13:40.921397Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = lgb.plot_importance(model, max_num_features=len(features), importance_type='gain', figsize=(12,8))\n",
    "ax.set(title=f'Feature Importance (split)',\n",
    "xlabel='Feature Importance',\n",
    "ylabel='Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
